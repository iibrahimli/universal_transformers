{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, \"..\")\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "from model import UniversalTransformer\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT-2 uses BPE\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = UniversalTransformer(\n",
    "    source_vocab_size=tokenizer.vocab_size,\n",
    "    target_vocab_size=tokenizer.vocab_size,\n",
    "    d_model=512,\n",
    "    n_heads=8,\n",
    "    d_feedforward=2048,\n",
    "    max_seq_len=100,\n",
    "    max_time_step=10,\n",
    "    halting_thresh=0.8\n",
    ")\n",
    "\n",
    "# load checkpoint\n",
    "checkpoint_path = \"../checkpoints/latest.pt\"\n",
    "cp = torch.load(checkpoint_path, map_location=\"cpu\")\n",
    "model.load_state_dict(cp[\"model_state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [\n",
    "    { \"de\": \"Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.\", \"en\": \"You have requested a debate on this subject in the course of the next few days, during this part-session.\" },\n",
    "    { \"de\": \"Heute möchte ich Sie bitten - das ist auch der Wunsch einiger Kolleginnen und Kollegen -, allen Opfern der Stürme, insbesondere in den verschiedenen Ländern der Europäischen Union, in einer Schweigeminute zu gedenken.\", \"en\": \"In the meantime, I should like to observe a minute' s silence, as a number of Members have requested, on behalf of all the victims concerned, particularly those of the terrible storms, in the various countries of the European Union.\" },\n",
    "    { \"de\": \"Ich bitte Sie, sich zu einer Schweigeminute zu erheben.\", \"en\": \"Please rise, then, for this minute' s silence.\" }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('You have requested a debate on this subject in the course of the next few days, during this part-session.',\n",
       " tensor([[ 1639,   423,  9167,   257,  4384,   319,   428,  2426,   287,   262,\n",
       "           1781,   286,   262,  1306,  1178,  1528,    11,  1141,   428,   636,\n",
       "             12, 29891,    13, 50256]]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source = samples[0][\"en\"]\n",
    "target = samples[0][\"de\"]\n",
    "source_ids = tokenizer(\n",
    "    [source + tokenizer.eos_token],\n",
    "    max_length=100,\n",
    "    truncation=True,\n",
    "    return_tensors=\"pt\",\n",
    ").input_ids\n",
    "source, source_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated = model.generate(\n",
    "    source_ids,\n",
    "    tokenizer.eos_token_id,\n",
    "    n_beams=0,\n",
    "    use_sampling=True,\n",
    "    temperature=0.8,\n",
    "    top_k=75,\n",
    "    top_p=0.8,\n",
    ")\n",
    "generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sie haben eine Debatte über die Tage in diesen Tagen, im nächsten Tage während dieses Berichts bei den Tagungen vorgesehen.',\n",
       " 'Im Parlament besteht der Wunsch nach einer Aussprache im Verlauf dieser Sitzungsperiode in den nächsten Tagen.')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = tokenizer.decode(generated, skip_special_tokens=True, clean_up_tokenization_spaces=True)\n",
    "output, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('dl_venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "68452a28a195af56f6fef09a39bddd84c9851e5010b5d65c56472b3e191520a0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
